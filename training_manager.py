"""
è®­ç»ƒç®¡ç†ç³»ç»Ÿ
æ•´åˆè‡ªæˆ‘å¯¹å¼ˆã€æ•°æ®ç®¡ç†ã€åˆ†æå’Œå¯è§†åŒ–åŠŸèƒ½

ä½œè€…ï¼šClaude AI Engineer
æ—¥æœŸï¼š2025-09-22
"""

import argparse
import json
import time
import sys
from pathlib import Path
from typing import Dict, List, Optional

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(str(Path(__file__).parent))

from auto_selfplay import AutoSelfPlay
from data_analyzer import DataAnalyzer
from data_visualizer import DataVisualizer
from data_manager import DataManager
from training_data_collector import TrainingDataCollector
from self_play_engine import SelfPlayConfig

class TrainingManager:
    """è®­ç»ƒç®¡ç†ç³»ç»Ÿ"""
    
    def __init__(self, workspace_dir: str = "training_workspace"):
        """
        åˆå§‹åŒ–è®­ç»ƒç®¡ç†ç³»ç»Ÿ
        
        Args:
            workspace_dir: å·¥ä½œç©ºé—´ç›®å½•
        """
        self.workspace_dir = Path(workspace_dir)
        self.workspace_dir.mkdir(exist_ok=True)
        
        # å­ç›®å½•
        self.data_dir = self.workspace_dir / "data"
        self.models_dir = self.workspace_dir / "models"
        self.analysis_dir = self.workspace_dir / "analysis"
        self.reports_dir = self.workspace_dir / "reports"
        
        # åˆ›å»ºç›®å½•ç»“æ„
        for dir_path in [self.data_dir, self.models_dir, self.analysis_dir, self.reports_dir]:
            dir_path.mkdir(exist_ok=True)
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.data_manager = DataManager(str(self.data_dir))
        self.data_analyzer = DataAnalyzer(str(self.data_dir))
        self.data_visualizer = DataVisualizer()
        
        # çŠ¶æ€è·Ÿè¸ª
        self.training_session = {
            'session_id': int(time.time()),
            'start_time': time.time(),
            'phases_completed': [],
            'current_phase': None,
            'status': 'initialized'
        }
        
        print(f"ğŸš€ è®­ç»ƒç®¡ç†ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
        print(f"ğŸ“ å·¥ä½œç©ºé—´: {self.workspace_dir}")
    
    def run_selfplay_training(self, config: Dict) -> Dict:
        """
        è¿è¡Œè‡ªæˆ‘å¯¹å¼ˆè®­ç»ƒ
        
        Args:
            config: è‡ªæˆ‘å¯¹å¼ˆé…ç½®
            
        Returns:
            è®­ç»ƒç»“æœ
        """
        print("\\n" + "="*60)
        print("ğŸ® å¼€å§‹è‡ªæˆ‘å¯¹å¼ˆè®­ç»ƒé˜¶æ®µ")
        print("="*60)
        
        self.training_session['current_phase'] = 'selfplay'
        
        # åˆ›å»ºè‡ªæˆ‘å¯¹å¼ˆé…ç½®
        selfplay_config = SelfPlayConfig(**config)
        
        # è¿è¡Œè‡ªæˆ‘å¯¹å¼ˆ
        auto_play = AutoSelfPlay()
        auto_play.config = selfplay_config
        
        results = auto_play.run(
            mode=config.get('mode', 'single'),
            output_dir=str(self.data_dir)
        )
        
        if results:
            self.training_session['phases_completed'].append('selfplay')
            print("âœ… è‡ªæˆ‘å¯¹å¼ˆè®­ç»ƒå®Œæˆ")
        else:
            print("âŒ è‡ªæˆ‘å¯¹å¼ˆè®­ç»ƒå¤±è´¥")
        
        return results
    
    def run_data_analysis(self, file_pattern: str = "*.json") -> Dict:
        """
        è¿è¡Œæ•°æ®åˆ†æ
        
        Args:
            file_pattern: æ–‡ä»¶æ¨¡å¼
            
        Returns:
            åˆ†æç»“æœ
        """
        print("\\n" + "="*60)
        print("ğŸ“Š å¼€å§‹æ•°æ®åˆ†æé˜¶æ®µ")
        print("="*60)
        
        self.training_session['current_phase'] = 'analysis'
        
        # è¿è¡Œå®Œæ•´åˆ†æ
        analysis_output = self.analysis_dir / f"session_{self.training_session['session_id']}"
        results = self.data_analyzer.run_full_analysis(
            file_pattern=file_pattern,
            output_dir=str(analysis_output)
        )
        
        if results:
            self.training_session['phases_completed'].append('analysis')
            print("âœ… æ•°æ®åˆ†æå®Œæˆ")
        else:
            print("âŒ æ•°æ®åˆ†æå¤±è´¥")
        
        return results
    
    def run_data_management(self, operations: List[str]) -> Dict:
        """
        è¿è¡Œæ•°æ®ç®¡ç†æ“ä½œ
        
        Args:
            operations: æ“ä½œåˆ—è¡¨ ['clean', 'split', 'augment', 'merge']
            
        Returns:
            æ“ä½œç»“æœ
        """
        print("\\n" + "="*60)
        print("ğŸ—‚ï¸ å¼€å§‹æ•°æ®ç®¡ç†é˜¶æ®µ")
        print("="*60)
        
        self.training_session['current_phase'] = 'data_management'
        results = {}
        
        # æ·»åŠ æ•°æ®æ–‡ä»¶åˆ°ç®¡ç†å™¨
        data_files = list(self.data_dir.glob("*.json"))
        for data_file in data_files:
            self.data_manager.add_data_file(str(data_file))
        
        # æ‰§è¡Œæ“ä½œ
        if 'clean' in operations:
            print("ğŸ§¹ æ¸…ç†æ•°æ®...")
            clean_results = self.data_manager.clean_data({
                'min_game_length': 10,
                'max_game_length': 400,
                'min_thinking_time': 0.1,
                'remove_duplicates': True
            })
            results['clean'] = clean_results
        
        if 'split' in operations:
            print("âœ‚ï¸ åˆ†å‰²æ•°æ®é›†...")
            split_results = self.data_manager.split_dataset(
                train_ratio=0.8, val_ratio=0.1, test_ratio=0.1
            )
            results['split'] = split_results
        
        if 'augment' in operations and 'split' in results:
            print("ğŸ”„ æ•°æ®å¢å¼º...")
            aug_results = self.data_manager.augment_dataset(
                results['split']['train_file'],
                str(self.data_dir / "augmented_train.json"),
                augmentation_factor=4
            )
            results['augment'] = aug_results
        
        if 'export' in operations:
            print("ğŸ“¤ å¯¼å‡ºè®­ç»ƒæ ·æœ¬...")
            export_dir = self.data_dir / "exported_samples"
            export_results = self.data_manager.export_training_samples(
                str(self.data_dir / "augmented_train.json") if 'augment' in results 
                else results.get('split', {}).get('train_file', ''),
                str(export_dir),
                format_type="numpy"
            )
            results['export'] = export_results
        
        if results:
            self.training_session['phases_completed'].append('data_management')
            print("âœ… æ•°æ®ç®¡ç†å®Œæˆ")
        
        return results
    
    def generate_comprehensive_report(self) -> str:
        """
        ç”Ÿæˆç»¼åˆè®­ç»ƒæŠ¥å‘Š
        
        Returns:
            æŠ¥å‘Šæ–‡ä»¶è·¯å¾„
        """
        print("\\n" + "="*60)
        print("ğŸ“ ç”Ÿæˆç»¼åˆè®­ç»ƒæŠ¥å‘Š")
        print("="*60)
        
        timestamp = int(time.time())
        report_file = self.reports_dir / f"training_report_{timestamp}.md"
        
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write("# äº”å­æ£‹AIè®­ç»ƒç»¼åˆæŠ¥å‘Š\\n\\n")
            
            # ä¼šè¯ä¿¡æ¯
            f.write("## è®­ç»ƒä¼šè¯ä¿¡æ¯\\n\\n")
            f.write(f"- **ä¼šè¯ID**: {self.training_session['session_id']}\\n")
            f.write(f"- **å¼€å§‹æ—¶é—´**: {time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(self.training_session['start_time']))}\\n")
            f.write(f"- **æ€»è€—æ—¶**: {time.time() - self.training_session['start_time']:.2f} ç§’\\n")
            f.write(f"- **å®Œæˆé˜¶æ®µ**: {', '.join(self.training_session['phases_completed'])}\\n")
            f.write(f"- **å·¥ä½œç©ºé—´**: {self.workspace_dir}\\n\\n")
            
            # æ•°æ®ç»Ÿè®¡
            f.write("## æ•°æ®ç»Ÿè®¡æ¦‚è§ˆ\\n\\n")
            stats = self.data_manager.get_data_statistics()
            f.write(f"- **æ€»æ¸¸æˆæ•°**: {stats.total_games:,}\\n")
            f.write(f"- **æ€»ç§»åŠ¨æ•°**: {stats.total_moves:,}\\n")
            f.write(f"- **å¹³å‡æ¸¸æˆé•¿åº¦**: {stats.avg_game_length:.1f}\\n")
            f.write(f"- **æ•°æ®å¤§å°**: {stats.data_size_mb:.2f} MB\\n")
            f.write(f"- **é»‘æ£‹èƒœç‡**: {stats.black_wins / max(1, stats.total_games) * 100:.1f}%\\n")
            f.write(f"- **ç™½æ£‹èƒœç‡**: {stats.white_wins / max(1, stats.total_games) * 100:.1f}%\\n")
            f.write(f"- **å¹³å±€ç‡**: {stats.draws / max(1, stats.total_games) * 100:.1f}%\\n\\n")
            
            # æ–‡ä»¶åˆ—è¡¨
            f.write("## ç”Ÿæˆçš„æ–‡ä»¶\\n\\n")
            f.write("### æ•°æ®æ–‡ä»¶\\n")
            for data_file in self.data_dir.glob("*"):
                f.write(f"- `{data_file.name}` ({data_file.stat().st_size / 1024:.1f} KB)\\n")
            
            f.write("\\n### åˆ†æç»“æœ\\n")
            for analysis_file in self.analysis_dir.rglob("*"):
                if analysis_file.is_file():
                    f.write(f"- `{analysis_file.relative_to(self.workspace_dir)}`\\n")
            
            f.write("\\n## ä½¿ç”¨å»ºè®®\\n\\n")
            f.write("1. **æ•°æ®è´¨é‡**: å»ºè®®å®šæœŸæ¸…ç†å’ŒéªŒè¯è®­ç»ƒæ•°æ®\\n")
            f.write("2. **æ¨¡å‹è®­ç»ƒ**: ä½¿ç”¨å¯¼å‡ºçš„numpyæ ¼å¼æ•°æ®è¿›è¡Œç¥ç»ç½‘ç»œè®­ç»ƒ\\n")
            f.write("3. **è¶…å‚æ•°è°ƒä¼˜**: æ ¹æ®åˆ†æç»“æœè°ƒæ•´MCTSå‚æ•°\\n")
            f.write("4. **æŒç»­æ”¹è¿›**: å®šæœŸé‡æ–°è¿è¡Œè‡ªæˆ‘å¯¹å¼ˆä»¥è·å–æ›´å¤šæ•°æ®\\n\\n")
            
            f.write("## ä¸‹ä¸€æ­¥æ“ä½œ\\n\\n")
            f.write("```bash\\n")
            f.write("# ä½¿ç”¨è®­ç»ƒæ•°æ®è®­ç»ƒç¥ç»ç½‘ç»œ\\n")
            f.write("python train_neural_network.py --data-dir training_workspace/data/exported_samples\\n")
            f.write("\\n")
            f.write("# è¯„ä¼°æ¨¡å‹æ€§èƒ½\\n")
            f.write("python evaluate_model.py --model-path training_workspace/models/latest.pth\\n")
            f.write("\\n")
            f.write("# ç»§ç»­è‡ªæˆ‘å¯¹å¼ˆè®­ç»ƒ\\n")
            f.write("python auto_selfplay.py --games 1000 --output-dir training_workspace/data\\n")
            f.write("```\\n")
        
        print(f"âœ… ç»¼åˆæŠ¥å‘Šå·²ç”Ÿæˆ: {report_file}")
        return str(report_file)
    
    def run_full_pipeline(self, pipeline_config: Dict) -> Dict:
        """
        è¿è¡Œå®Œæ•´è®­ç»ƒæµæ°´çº¿
        
        Args:
            pipeline_config: æµæ°´çº¿é…ç½®
            
        Returns:
            æ‰§è¡Œç»“æœ
        """
        print("\\n" + "ğŸŒŸ"*30)
        print("ğŸš€ å¼€å§‹å®Œæ•´è®­ç»ƒæµæ°´çº¿")
        print("ğŸŒŸ"*30)
        
        results = {}
        
        try:
            # 1. è‡ªæˆ‘å¯¹å¼ˆè®­ç»ƒ
            if pipeline_config.get('run_selfplay', True):
                selfplay_results = self.run_selfplay_training(
                    pipeline_config.get('selfplay_config', {})
                )
                results['selfplay'] = selfplay_results
            
            # 2. æ•°æ®ç®¡ç†
            if pipeline_config.get('run_data_management', True):
                management_results = self.run_data_management(
                    pipeline_config.get('management_operations', ['clean', 'split', 'augment', 'export'])
                )
                results['data_management'] = management_results
            
            # 3. æ•°æ®åˆ†æ
            if pipeline_config.get('run_analysis', True):
                analysis_results = self.run_data_analysis()
                results['analysis'] = analysis_results
            
            # 4. ç”ŸæˆæŠ¥å‘Š
            if pipeline_config.get('generate_report', True):
                report_file = self.generate_comprehensive_report()
                results['report'] = report_file
            
            self.training_session['status'] = 'completed'
            print("\\nğŸ‰ å®Œæ•´è®­ç»ƒæµæ°´çº¿æ‰§è¡Œå®Œæˆ!")
            
        except Exception as e:
            self.training_session['status'] = 'failed'
            print(f"\\nâŒ è®­ç»ƒæµæ°´çº¿æ‰§è¡Œå¤±è´¥: {e}")
            results['error'] = str(e)
        
        return results
    
    def save_session_config(self, config: Dict):
        """ä¿å­˜ä¼šè¯é…ç½®"""
        config_file = self.workspace_dir / f"session_{self.training_session['session_id']}_config.json"
        with open(config_file, 'w', encoding='utf-8') as f:
            json.dump(config, f, indent=2, ensure_ascii=False)
    
    def load_session_config(self, session_id: int) -> Optional[Dict]:
        """åŠ è½½ä¼šè¯é…ç½®"""
        config_file = self.workspace_dir / f"session_{session_id}_config.json"
        if config_file.exists():
            with open(config_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        return None

def create_default_config() -> Dict:
    """åˆ›å»ºé»˜è®¤é…ç½®"""
    return {
        'selfplay_config': {
            'num_games': 100,
            'mcts_simulations': 800,
            'thinking_time_limit': 3.0,
            'temperature': 1.0,
            'temperature_decay': 0.95,
            'min_temperature': 0.1,
            'parallel_games': 1,
            'max_threads': 4,
            'mode': 'single'
        },
        'management_operations': ['clean', 'split', 'augment', 'export'],
        'run_selfplay': True,
        'run_data_management': True,
        'run_analysis': True,
        'generate_report': True
    }

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="äº”å­æ£‹AIè®­ç»ƒç®¡ç†ç³»ç»Ÿ")
    
    parser.add_argument("--workspace", type=str, default="training_workspace",
                       help="å·¥ä½œç©ºé—´ç›®å½• (é»˜è®¤: training_workspace)")
    parser.add_argument("--config", type=str,
                       help="é…ç½®æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--games", type=int, default=100,
                       help="è‡ªæˆ‘å¯¹å¼ˆæ¸¸æˆæ•° (é»˜è®¤: 100)")
    parser.add_argument("--simulations", type=int, default=800,
                       help="MCTSæ¨¡æ‹Ÿæ¬¡æ•° (é»˜è®¤: 800)")
    parser.add_argument("--mode", choices=["single", "multi", "batch"], 
                       default="single", help="è¿è¡Œæ¨¡å¼")
    parser.add_argument("--skip-selfplay", action="store_true",
                       help="è·³è¿‡è‡ªæˆ‘å¯¹å¼ˆé˜¶æ®µ")
    parser.add_argument("--skip-analysis", action="store_true",
                       help="è·³è¿‡æ•°æ®åˆ†æé˜¶æ®µ")
    parser.add_argument("--only-report", action="store_true",
                       help="ä»…ç”ŸæˆæŠ¥å‘Š")
    
    args = parser.parse_args()
    
    # åˆ›å»ºè®­ç»ƒç®¡ç†å™¨
    manager = TrainingManager(args.workspace)
    
    # åŠ è½½æˆ–åˆ›å»ºé…ç½®
    if args.config and Path(args.config).exists():
        with open(args.config, 'r', encoding='utf-8') as f:
            config = json.load(f)
    else:
        config = create_default_config()
        
        # æ›´æ–°é…ç½®
        config['selfplay_config'].update({
            'num_games': args.games,
            'mcts_simulations': args.simulations,
            'mode': args.mode
        })
        
        config['run_selfplay'] = not args.skip_selfplay
        config['run_analysis'] = not args.skip_analysis
    
    # ä¿å­˜é…ç½®
    manager.save_session_config(config)
    
    if args.only_report:
        # ä»…ç”ŸæˆæŠ¥å‘Š
        report_file = manager.generate_comprehensive_report()
        print(f"\\nğŸ“ æŠ¥å‘Šå·²ç”Ÿæˆ: {report_file}")
    else:
        # è¿è¡Œå®Œæ•´æµæ°´çº¿
        results = manager.run_full_pipeline(config)
        
        if results.get('error'):
            print(f"\\nâŒ æ‰§è¡Œå¤±è´¥: {results['error']}")
            sys.exit(1)
        else:
            print(f"\\nâœ… è®­ç»ƒç®¡ç†ä»»åŠ¡å®Œæˆ!")
            print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {manager.workspace_dir}")

if __name__ == "__main__":
    main()